import pandas as pd
import ollama
import json
from typing import Dict, Any, Optional
import os
from datetime import datetime

class OllamaAnalyzer:
    def __init__(self, model: str = "mistral:instruct"):
        self.model = model
        self.exemplos_manuais = []

    def add_exemplo_manual(self, letra: str, score: str, justificativa: str):
        """Adiciona um exemplo de classifica√ß√£o manual para aprendizado"""
        self.exemplos_manuais.append({
            "letra": letra,
            "score": score,
            "justificativa": justificativa
        })

    def gerar_prompt_com_exemplos(self, prompt_base: str) -> str:
        """Gera o prompt completo incluindo os exemplos de classifica√ß√£o manual"""
        prompt_completo = prompt_base + "\n\n=== EXEMPLOS DE REFER√äNCIA ===\n"
        prompt_completo += "Analise cuidadosamente os seguintes exemplos j√° classificados. Eles devem servir como base para suas pr√≥ximas classifica√ß√µes.\n"

        for exemplo in self.exemplos_manuais:
            prompt_completo += "\n---\nEXEMPLO DE CLASSIFICA√á√ÉO:\n"
            prompt_completo += f"Letra:\n{exemplo['letra']}\n\n"
            prompt_completo += f"Nivel de toxicidade: {exemplo['score']}\n"
            prompt_completo += f"Justificativa: {exemplo['justificativa']}\n"
            prompt_completo += "---\n"
        
        prompt_completo += "\nAgora, use esses exemplos como refer√™ncia para classificar a pr√≥xima m√∫sica de forma similar.\n"
        return prompt_completo

    def parse_response(self, response: str) -> Dict[str, Any]:
        """Tenta converter a resposta do modelo em um dicion√°rio estruturado"""
        print(f"Resposta recebida: {response[:200]}...")  # Debug
        
        try:
            # Primeiro tenta parsear como JSON direto
            return json.loads(response)
        except json.JSONDecodeError:
            # Se falhar, tenta extrair os campos do texto
            result = {
                "nivel_toxicidade": "na",
                "abuso_emocional": False,
                "ciume_possessividade": False,
                "dependencia": False,
                "objetificacao": False,
                "violencia_traicao": False,
                "justificativa": ""
            }
            
            # Procura por JSON embeddado na resposta
            json_start = response.find('{')
            json_end = response.rfind('}')
            if json_start != -1 and json_end != -1 and json_end > json_start:
                try:
                    json_part = response[json_start:json_end+1]
                    return json.loads(json_part)
                except json.JSONDecodeError:
                    pass
            
            # Parse manual mais robusto
            lines = response.split('\n')
            justificativa_lines = []
            capturing_justificativa = False
            
            for line in lines:
                line_clean = line.strip()
                line_lower = line_clean.lower()
                
                if line_lower.startswith('nivel de toxicidade:') or line_lower.startswith('n√≠vel de toxicidade:'):
                    nivel = line_clean.split(':', 1)[1].strip().lower()
                    if 'muito alto' in nivel:
                        result['nivel_toxicidade'] = 'muito alto'
                    elif 'muito baixo' in nivel:
                        result['nivel_toxicidade'] = 'muito baixo'
                    elif 'alto' in nivel:
                        result['nivel_toxicidade'] = 'alto'
                    elif 'baixo' in nivel:
                        result['nivel_toxicidade'] = 'baixo'
                    elif 'moderado' in nivel:
                        result['nivel_toxicidade'] = 'moderado'
                    elif 'na' in nivel or 'n√£o aplic√°vel' in nivel:
                        result['nivel_toxicidade'] = 'na'
                        
                elif line_lower.startswith('abuso_emocional:'):
                    val = line_clean.split(':', 1)[1].strip().lower()
                    result['abuso_emocional'] = 'yes' in val or 'sim' in val or 'true' in val
                    
                elif line_lower.startswith('ciume_possessividade:'):
                    val = line_clean.split(':', 1)[1].strip().lower()
                    result['ciume_possessividade'] = 'yes' in val or 'sim' in val or 'true' in val
                    
                elif line_lower.startswith('dependencia:') or line_lower.startswith('depend√™ncia:'):
                    val = line_clean.split(':', 1)[1].strip().lower()
                    result['dependencia'] = 'yes' in val or 'sim' in val or 'true' in val
                    
                elif line_lower.startswith('objetificacao:') or line_lower.startswith('objetifica√ß√£o:'):
                    val = line_clean.split(':', 1)[1].strip().lower()
                    result['objetificacao'] = 'yes' in val or 'sim' in val or 'true' in val
                    
                elif line_lower.startswith('violencia_traicao:') or line_lower.startswith('viol√™ncia_trai√ß√£o:'):
                    val = line_clean.split(':', 1)[1].strip().lower()
                    result['violencia_traicao'] = 'yes' in val or 'sim' in val or 'true' in val
                    
                elif line_lower.startswith('justificativa:'):
                    capturing_justificativa = True
                    just_content = line_clean.split(':', 1)[1].strip()
                    if just_content:
                        justificativa_lines.append(just_content)
                        
                elif capturing_justificativa and line_clean:
                    justificativa_lines.append(line_clean)
            
            if justificativa_lines:
                result['justificativa'] = ' '.join(justificativa_lines)
                
            print(f"Resultado parseado: {result}")  # Debug
            return result

    def is_valid_response(self, result: Dict[str, Any]) -> bool:
        """Valida se a resposta cont√©m os campos necess√°rios e n√£o est√° vazia"""
        if not result:
            return False
            
        # Verifica se tem n√≠vel de toxicidade v√°lido
        valid_levels = ['na', 'muito baixo', 'baixo', 'moderado', 'alto', 'muito alto']
        if result.get('nivel_toxicidade', '').lower() not in valid_levels:
            return False
            
        # Se o n√≠vel n√£o √© 'na', deve ter justificativa
        if result.get('nivel_toxicidade', '').lower() != 'na' and not result.get('justificativa', '').strip():
            return False
            
        return True

    def analyze_text(self, text: str, prompt: str, max_retries: int = 3) -> Optional[Dict[str, Any]]:
        """Analisa texto com retry autom√°tico em caso de resposta inv√°lida"""
        for attempt in range(max_retries):
            try:
                print(f"Tentativa {attempt + 1}/{max_retries}")
                
                full_prompt = f"{self.gerar_prompt_com_exemplos(prompt)}\n\nAGORA ANALISE ESTA LETRA:\n{text}"

                response = ollama.generate(
                    model=self.model,
                    prompt=full_prompt,
                    options={
                        'temperature': 0.1,  # Consist√™ncia
                        'num_ctx': 8192,     # Contexto maior
                        'num_predict': 1500, # Mais tokens para resposta
                        'top_p': 0.9,        # Controle de criatividade
                        'repeat_penalty': 1.1  # Evita repeti√ß√£o
                    }
                )
                
                if response and response.get('response'):
                    result = self.parse_response(response['response'].strip())
                    
                    if self.is_valid_response(result):
                        print(f"‚úÖ Resposta v√°lida obtida na tentativa {attempt + 1}")
                        return result
                    else:
                        print(f"‚ö†Ô∏è Resposta inv√°lida na tentativa {attempt + 1}: {result}")
                        
                else:
                    print(f"‚ö†Ô∏è Resposta vazia na tentativa {attempt + 1}")
                    
            except Exception as e:
                print(f"‚ùå Erro na tentativa {attempt + 1}: {e}")
                
        print(f"‚ùå Falha ap√≥s {max_retries} tentativas")
        return None

def carregar_exemplos_manuais(analyzer: OllamaAnalyzer, csv_path: str):
    """Carrega os exemplos de classifica√ß√£o manual para o analisador"""
    try:
        df_manual = pd.read_csv(csv_path)
        print(f"\nCarregando {len(df_manual)} exemplos de classifica√ß√£o manual...")
        
        for idx, row in df_manual.iterrows():
            try:
                letra = row['Letra'] if 'Letra' in df_manual.columns else None
                nivel = row['Pontuacao_manual'] if 'Pontuacao_manual' in df_manual.columns else None
                justificativa = row['Justificativa'] if 'Justificativa' in df_manual.columns else None
                
                if letra is not None and nivel is not None:
                    analyzer.add_exemplo_manual(
                        letra=letra,
                        score=nivel,
                        justificativa=str(justificativa) if justificativa is not None else ""
                    )
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao processar exemplo {idx}: {e}")
                continue
        
        print("‚úÖ Exemplos manuais carregados com sucesso!")
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao carregar exemplos manuais: {e}")

def analise_conteudo_toxico(df: pd.DataFrame) -> pd.DataFrame:
    print("\nColunas dispon√≠veis no dataset:")
    print(df.columns.tolist())

    coluna_titulo = 'Song Title'
    coluna_artista = 'Artist'
    coluna_letra = 'Lyrics'
    coluna_ano = 'Year'

    prompt = """
    Voc√™ √© um especialista em an√°lise cr√≠tica de letras de m√∫sicas. Sua tarefa √© identificar elementos t√≥xicos em relacionamentos amorosos.

    REGRAS OBRIGAT√ìRIAS:
    1. VOC√ä DEVE responder EXATAMENTE no formato especificado abaixo
    2. VOC√ä DEVE classificar cada m√∫sica em um √∫nico n√≠vel de toxicidade
    3. VOC√ä DEVE citar trechos espec√≠ficos da letra quando aplic√°vel
    4. **SE TODOS os elementos forem marcados como "no", o N√≠vel de Toxicidade OBRIGATORIAMENTE deve ser "na"**

    N√çVEIS DE TOXICIDADE (escolha UM):
    ‚Ä¢ muito alto - M√∫ltiplos elementos t√≥xicos graves
    ‚Ä¢ alto - Elementos t√≥xicos significativos  
    ‚Ä¢ moderado - Alguns elementos problem√°ticos
    ‚Ä¢ baixo - Poucos elementos question√°veis
    ‚Ä¢ muito baixo - Elementos m√≠nimos ou amb√≠guos
    ‚Ä¢ na - Sem elementos t√≥xicos (amor saud√°vel, saudade normal)

    ELEMENTOS T√ìXICOS A IDENTIFICAR:
    ‚Ä¢ abuso_emocional: gaslighting, chantagem, manipula√ß√£o, culpabiliza√ß√£o
    ‚Ä¢ ciume_possessividade: controle, posse, restri√ß√£o da liberdade
    ‚Ä¢ dependencia: necessidade excessiva, incapacidade de ficar sozinho
    ‚Ä¢ objetificacao: redu√ß√£o a objeto sexual/de posse
    ‚Ä¢ violencia_traicao: viol√™ncia f√≠sica/psicol√≥gica, amea√ßas

    REGRA IMPORTANTE:
    ‚ö†Ô∏è Se TODOS os campos abaixo forem "no", o N√≠vel de Toxicidade DEVE ser "na".

    FORMATO OBRIGAT√ìRIO DA RESPOSTA (copie exatamente):
    Nivel de toxicidade: [sua escolha aqui]
    abuso_emocional: [yes ou no]
    ciume_possessividade: [yes ou no] 
    dependencia: [yes ou no]
    objetificacao: [yes ou no]
    violencia_traicao: [yes ou no]
    justificativa: [cite trechos espec√≠ficos e explique OU escreva "nenhum elemento t√≥xico identificado"]

   IMPORTANTE:
    - Se todos os elementos forem "no", o n√≠vel de toxicidade **deve** ser "na"
    - Se algum elemento for "yes", voc√™ deve obrigatoriamente justificar com trechos da letra
    - N√£o penalize amor normal, saudade ou desejo saud√°vel
    - Para BDSM, s√≥ considere t√≥xico se claramente n√£o consensual
    """

    analyzer = OllamaAnalyzer()
    
    # Carrega exemplos de classifica√ß√£o manual
    carregar_exemplos_manuais(analyzer, '../data/30-musicas-Mozart.csv')

    resultados = []
    os.makedirs("results", exist_ok=True)

    # TESTE: Limita a 3 m√∫sicas para validar melhorias
    total = len(df)
    print(f"üß™ MODO TESTE: Analisando apenas {total} m√∫sicas para validar melhorias")
    
    for idx, row in df.head(total).iterrows():
        print(f"\nAnalisando {idx + 1}/{total} - {row[coluna_titulo]}")

        result = analyzer.analyze_text(row[coluna_letra], prompt)
        if result:
            try:
                resultados.append({
                    "indice": idx,
                    "titulo": row[coluna_titulo],
                    "artista": row[coluna_artista],
                    "ano": row[coluna_ano] if coluna_ano in df.columns else None,
                    "nivel_toxicidade": result.get("nivel_toxicidade", "NA"),
                    "abuso_emocional": result.get("abuso_emocional", False),
                    "ciume_possessividade": result.get("ciume_possessividade", False),
                    "dependencia": result.get("dependencia", False),
                    "objetificacao": result.get("objetificacao", False),
                    "violencia_traicao": result.get("violencia_traicao", False),
                    "justificativa": result.get("justificativa", "")
                })

                print(f"‚Üí N√≠vel de toxicidade: {result.get('nivel_toxicidade', 'NA')}")

                # Salva a cada 5 an√°lises
                if (idx + 1) % 5 == 0:
                    parcial_path = f"results/parcial_{idx + 1}.csv"
                    pd.DataFrame(resultados).to_csv(parcial_path, index=False)
                    print(f"[Salvo parcial em: {parcial_path}]")

            except Exception as e:
                print(f"Erro ao processar resultado: {e}")
        else:
            print("Resposta nula do modelo.")

    return pd.DataFrame(resultados)

def main():
    try:
        print("\nüìä Carregando dataset de m√∫sicas classificadas...")
        df_manual = pd.read_csv("../data/30-musicas-Mozart.csv")
        
        print("\nüìä Carregando dataset de m√∫sicas para an√°lise...")
        df = pd.read_csv("../data/all_songs_data.csv")
    except Exception as e:
        print(f"Erro ao carregar o dataset: {e}")
        return

    print("\nAnalisando m√∫sicas para conte√∫do t√≥xico em relacionamentos")
    print("=" * 60)
    print("Modelo em uso: mistral:instruct")
    print("=" * 60)

    resultados_df = analise_conteudo_toxico(df)

    if resultados_df.empty:
        print("Nenhum resultado retornado.")
        return

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_path = f'results/relacionamentos_toxicos_{timestamp}.csv'
    json_path = f'results/relacionamentos_toxicos_{timestamp}.json'

    resultados_df.to_csv(csv_path, index=False)
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(resultados_df.to_dict(orient='records'), f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ An√°lise completa!")
    print(f"Resultados salvos em:\n‚Üí CSV: {csv_path}\n‚Üí JSON: {json_path}")
    print(f"\nEstat√≠sticas:")
    print(f"‚Üí Total analisado: {len(resultados_df)}")
    
    # Contagem por n√≠vel de toxicidade
    niveis = resultados_df['nivel_toxicidade'].value_counts()
    print("\nDistribui√ß√£o por n√≠vel de toxicidade:")
    for nivel, count in niveis.items():
        print(f"‚Üí {nivel}: {count} m√∫sicas ({(count/len(resultados_df)*100):.1f}%)")
    
    # Contagem de elementos t√≥xicos
    print("\nPreval√™ncia de elementos t√≥xicos:")
    print(f"‚Üí Abuso emocional: {resultados_df['abuso_emocional'].sum()} m√∫sicas")
    print(f"‚Üí Ci√∫me/possessividade: {resultados_df['ciume_possessividade'].sum()} m√∫sicas")
    print(f"‚Üí Depend√™ncia: {resultados_df['dependencia'].sum()} m√∫sicas")
    print(f"‚Üí Objetifica√ß√£o: {resultados_df['objetificacao'].sum()} m√∫sicas")
    print(f"‚Üí Viol√™ncia/trai√ß√£o: {resultados_df['violencia_traicao'].sum()} m√∫sicas")

if __name__ == "__main__":
    main()
